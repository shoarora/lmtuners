model:
  generator_name: electra_small_generator
  discriminator_name: electra_small_discriminator
  tokenizer_path: google/electra-small-discriminator

  training:
    total_steps: ${trainer.max_steps}

data:
  dataset_path: wikipedia
  dataset_version: 20200501.en
  batch_size: 32
  num_workers: 4
  column: text
  block_size: null
  mlm_probability: 0.15
  pretokenize: false

trainer:
  gpus: 0
  fast_dev_run: false
  max_steps: 1e6
  limit_val_batches: 0.1
  val_check_interval: 0.1

logger:
  type: wandb
  args:
    name: electra-small-wikipedia
    project: transformers-trainers-v0.2.0
    log_model: true
